---
title: "Using annual Stack Overflow Developers Survey (2017) Predicting which Stack-Overflow Developers are more likely to work remotely."
author: "Ketan Bhadoriya"
output: html_document
---

######Note : Data Taken from Datacamp.com from a Supervised Learning Course and Case Study performed under the guidance of the Tutor Julia Silge Data Scientist at Stack Overflow.

###Loading the required packages and the Data

```{r,warning=FALSE,message=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(RCurl)
library(caret)

url_data <- "https://assets.datacamp.com/production/course_6013/datasets/stackoverflow.csv"

x <- getURL(url_data)

stackoverflow <- read.csv(textConnection(x))
```

###Exploring the Data

```{r,warning=FALSE,message=FALSE}
head(stackoverflow)

str(stackoverflow)

str(stackoverflow$Remote)

#Number of Developers in Each Country

stackoverflow %>% 
  count(Country, sort = TRUE)

#Number of Developers falls under Remote Working or Non-Remote working style

stackoverflow %>% 
  count(Remote, sort = TRUE)

#Visualizing the relationship between coding experience among developers and their working style

ggplot(stackoverflow, aes(Remote, YearsCodedJob)) +
  geom_boxplot() +
  labs(x = NULL,
       y = "Years of professional coding experience") 
```

**Comment : There is large the imbalance between remote and non-remote workers in this dataset.**

###Building a simple logistic regression model

```{r,warning=FALSE,message=FALSE}
simple_glm <- stackoverflow %>%
  select(-Respondent) %>%
  glm(Remote ~ .,
      family = "binomial",
      data = .)

#Summary of the model

summary(simple_glm)
```

**Comment : From the summary of the aobove model we have an idea of which predictors have larger effect sizes and which are significant or not significant.**

###Splitting the data and then training the Model using caret package

```{r,warning=FALSE,message=FALSE}
stack_select <- stackoverflow %>%
  select(-Respondent)

# Splitting the data into training and testing sets
set.seed(1234)
in_train <- createDataPartition(stack_select$Remote, p = .8, list = FALSE)
training <- stack_select[in_train,]
testing <- stack_select[-in_train,]

#Now Upsampling the data to handle imbalance in case of Remote and Non-remote Developers
up_train <- upSample(x = select(training, -Remote),
                     y = training$Remote,
                     yname = "Remote") %>%
                            as_tibble()

up_train %>%
  count(Remote)

#We can see in the results imbalancment has been removed
```

